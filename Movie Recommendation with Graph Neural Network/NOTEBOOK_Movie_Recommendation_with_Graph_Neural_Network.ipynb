{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7-oJOCkGqXEU",
   "metadata": {
    "id": "7-oJOCkGqXEU"
   },
   "source": [
    "------------------------------------------------------------------------------------------\n",
    "# **Movie Recommendation using Graph Neural Networks**\n",
    "-------------------------------------------------------------------------------------\n",
    "\n",
    "## **Context**\n",
    "Online streaming platforms like Netflix have plenty of movies in their repositories and if we can build a recommendation system to recommend relevant movies to users based on their historical interactions, this would improve customer satisfaction and hence improve revenue. The techniques that we will learn here will not only be limited to movies, they can be implemented through a Graph Neural Networks for other problems as well.\n",
    "\n",
    "## **Objective**\n",
    "\n",
    "In this case study, we will be building a graph neural network (GNN) to suggest similar movies based on what movies a user has watched.\n",
    "\n",
    "## **Dataset**\n",
    "\n",
    "The 'ratings' dataset contains the following attributes:\n",
    "- userId\n",
    "- movieId\n",
    "- rating\n",
    "- timestamp\n",
    "\n",
    "We will also use the 'movies' dataset to get the title of the movies. It contains the following attributes:\n",
    "\n",
    "- movieId\n",
    "- title\n",
    "- genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d705b8ad",
   "metadata": {
    "id": "d705b8ad"
   },
   "source": [
    "## **Importing the necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ylb2uH7bnxxY",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:10.440862Z",
     "start_time": "2023-05-16T10:21:08.620491Z"
    },
    "id": "ylb2uH7bnxxY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import math\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Needed to silence tensorflow messages while running locally\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tisM4v-Eu0rb",
   "metadata": {
    "id": "tisM4v-Eu0rb"
   },
   "source": [
    "## **Retrieving the Datasets from the URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hkKAfivDnxxc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:12.726341Z",
     "start_time": "2023-05-16T10:21:11.811765Z"
    },
    "id": "hkKAfivDnxxc"
   },
   "outputs": [],
   "source": [
    "urlretrieve(\n",
    "    \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\", \"movielens.zip\"\n",
    ")\n",
    "\n",
    "ZipFile(\"movielens.zip\", \"r\").extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saWMXgf24Din",
   "metadata": {
    "id": "saWMXgf24Din"
   },
   "source": [
    "## **Converting the datasets into more readable format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aLgAmRbfnxxc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:13.482364Z",
     "start_time": "2023-05-16T10:21:13.403772Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLgAmRbfnxxc",
    "outputId": "1dec328c-dc69-4c31-99ed-10d2fe09f9be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies data shape: (9742, 3)\n",
      "Ratings data shape: (100836, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load movies to a DataFrame\n",
    "\n",
    "movies = pd.read_csv(\"ml-latest-small/movies.csv\")\n",
    "\n",
    "# Create a `movieId` string\n",
    "\n",
    "movies[\"movieId\"] = movies[\"movieId\"].apply(lambda x: f\"movie_{x}\")\n",
    "\n",
    "# Load ratings to a DataFrame\n",
    "\n",
    "ratings = pd.read_csv(\"ml-latest-small/ratings.csv\") \n",
    "\n",
    "# Convert the `ratings` to floating point\n",
    "\n",
    "ratings[\"rating\"] = ratings[\"rating\"].apply(lambda x: float(x))\n",
    "\n",
    "# Create the `movie_id` string\n",
    "\n",
    "ratings[\"movieId\"] = ratings[\"movieId\"].apply(lambda x: f\"movie_{x}\")\n",
    "\n",
    "print(\"Movies data shape:\", movies.shape)\n",
    "\n",
    "print(\"Ratings data shape:\", ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "p-IE1N3Znxxd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:14.209067Z",
     "start_time": "2023-05-16T10:21:14.203747Z"
    },
    "id": "p-IE1N3Znxxd"
   },
   "outputs": [],
   "source": [
    "# This function gives us the name of the movie from the movieId\n",
    "def get_movie_title_by_id(movieId):\n",
    "\n",
    "    return list(movies[movies.movieId == movieId].title)[0]  \n",
    "\n",
    "# This function gives us the id of the movie from the name of the movie\n",
    "def get_movie_id_by_title(title):\n",
    "\n",
    "    return list(movies[movies.title == title].movieId)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4Lvaa3oRnxxe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:14.932427Z",
     "start_time": "2023-05-16T10:21:14.914538Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4Lvaa3oRnxxe",
    "outputId": "9d01c1cc-f7eb-4770-b4e7-94701e980288"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=51a2ddd3-f066-4857-bb0b-b58ccb8d4b70 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('51a2ddd3-f066-4857-bb0b-b58ccb8d4b70').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>movie_1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>movie_3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>movie_6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>movie_47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>movie_50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "   userId   movieId  rating  timestamp\n",
       "0       1   movie_1     4.0  964982703\n",
       "1       1   movie_3     4.0  964981247\n",
       "2       1   movie_6     4.0  964982224\n",
       "3       1  movie_47     5.0  964983815\n",
       "4       1  movie_50     5.0  964982931"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the datasets\n",
    "ratings.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "V_1s_Htrnxxe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:15.625008Z",
     "start_time": "2023-05-16T10:21:15.609798Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "V_1s_Htrnxxe",
    "outputId": "37021bb1-5cf4-4e63-c5b2-bd7ba313ee39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=0de8f1cb-7c66-4668-acea-189ac4eadb06 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('0de8f1cb-7c66-4668-acea-189ac4eadb06').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie_1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie_2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie_3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie_4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie_5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0  movie_1                    Toy Story (1995)   \n",
       "1  movie_2                      Jumanji (1995)   \n",
       "2  movie_3             Grumpier Old Men (1995)   \n",
       "3  movie_4            Waiting to Exhale (1995)   \n",
       "4  movie_5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2BA5luOH9lR9",
   "metadata": {
    "id": "2BA5luOH9lR9"
   },
   "source": [
    "## **Calculating Pairwise and Item Frequency**\n",
    "\n",
    "Let's calculate item_frequency for each movie and pair_frequency for every possible pair of movies. We need these frequencies to build our Graph. The purpose of these frequencies is written below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "MUfIqnXBnxxf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:16.788307Z",
     "start_time": "2023-05-16T10:21:16.439724Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUfIqnXBnxxf",
    "outputId": "0e2eccb5-b70a-46d0-ef64-dace797f4205"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute movie rating frequencies: 100%|█████| 573/573 [00:00<00:00, 2379.91it/s]\n"
     ]
    }
   ],
   "source": [
    "min_rating = 5\n",
    "\n",
    "item_frequency = defaultdict(int)  # Dictionary to indicate how many times each movie has been watched\n",
    "\n",
    "pair_frequency = defaultdict(int)  # Dictionary to indicate how many times a particular pair of movies have been watched\n",
    "\n",
    "# Filter instances where the rating is greater than or equal to min_rating\n",
    "\n",
    "rated_movies = ratings[ratings.rating >= min_rating]\n",
    "\n",
    "# Group instances by the user. Here, each group contains movies watched by a particular user\n",
    "\n",
    "movies_grouped_by_users = list(rated_movies.groupby(\"userId\"))\n",
    "\n",
    "for group in tqdm(\n",
    "    \n",
    "    movies_grouped_by_users,\n",
    "    \n",
    "    position = 0,\n",
    "\n",
    "    leave = True,\n",
    "\n",
    "    desc = \"Compute movie rating frequencies\",\n",
    "\n",
    "):  # Iterating over all the groups\n",
    "\n",
    "    # Get a list of movies rated by the user\n",
    "\n",
    "    current_movies = list(group[1][\"movieId\"])\n",
    "\n",
    "    for i in range(len(current_movies)):\n",
    "\n",
    "        item_frequency[current_movies[i]] += 1  # Increasing count of item frequency for a particular movie on encountering it in a group\n",
    "        \n",
    "        for j in range(i + 1, len(current_movies)):\n",
    "            \n",
    "            x = min(current_movies[i], current_movies[j])\n",
    "            \n",
    "            y = max(current_movies[i], current_movies[j])\n",
    "            \n",
    "            pair_frequency[(x, y)] += 1  # Increasing count of pair frequency for a particular pair of movies on coming across it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e_avGuIK-Hsj",
   "metadata": {
    "id": "e_avGuIK-Hsj"
   },
   "source": [
    "In the cell above, we are creating two dictionaries:\n",
    "- The first dictionary, i.e., 'item_frequency' is the item frequency where we calculate the number of times each movie has been watched, assuming every user has watched any particular movie exactly once. \n",
    "- The second dictionary, i.e., 'pair_frequency' is the pair-wise frequency, where we see how many users have watched both of these movies. \n",
    "- A greater value indicates higher probability of one of these movies being suggested when any new user has watched the other movie in the pair, i.e, if the pair-wise frequency of movie A and movie B is high, and a new user happens to watch movie A, they are likely to be suggested movie B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HC9_7xvmNl2O",
   "metadata": {
    "id": "HC9_7xvmNl2O"
   },
   "source": [
    "## **Creating the Graph**\n",
    "\n",
    "We are trying to model what movies are frequently watched together based on all of the user data. To think of this more intuitively, the higher the weight of an edge between two movies A and B, the higher is the probability of movie B being suggested after you have watched movie A and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vPbIdGRTnxxg",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:20.143540Z",
     "start_time": "2023-05-16T10:21:19.867237Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPbIdGRTnxxg",
    "outputId": "e6459041-f486-4964-e8fd-65179c9df2b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating the movie graph: 100%|████| 298586/298586 [00:00<00:00, 1147097.09it/s]\n"
     ]
    }
   ],
   "source": [
    "min_weight = 10\n",
    "\n",
    "D = math.log(sum(item_frequency.values()))\n",
    "\n",
    "# Create the undirected graph with the movies as nodes\n",
    "\n",
    "movies_graph = nx.Graph()\n",
    "\n",
    "# Add weighted edges between movies\n",
    "\n",
    "# This automatically adds the movie nodes to the graph\n",
    "\n",
    "for pair in tqdm(\n",
    "\n",
    "    pair_frequency, position = 0, leave = True, desc = \"Creating the movie graph\"\n",
    "\n",
    "):  # Iterating over every pair of movies\n",
    "    x, y = pair  # Unpacking the tuple called 'pair' to receive the two movies\n",
    "\n",
    "    \n",
    "    xy_frequency = pair_frequency[pair]  # Pair-wise frequency of two particular movies\n",
    "    \n",
    "    x_frequency = item_frequency[x]  # Item frequency for the first movie in the pair\n",
    "    \n",
    "    y_frequency = item_frequency[y]  # Item frequency for the second movie in the pair\n",
    "\n",
    "    # Calculating PMI index as a measure of the pairing strength\n",
    "\n",
    "    pmi = math.log(xy_frequency) - math.log(x_frequency) - math.log(y_frequency) + D\n",
    "\n",
    "    weight = pmi * xy_frequency\n",
    "\n",
    "    # Only include edges with weight >= min_weight\n",
    "\n",
    "    if weight >= min_weight:\n",
    "\n",
    "        movies_graph.add_edge(x, y, weight = weight)  # Adding the edge to those particular nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pvNZ2cC9PEqj",
   "metadata": {
    "id": "pvNZ2cC9PEqj"
   },
   "source": [
    "To calculate the pairing strength between two movies, we are using the PMI index. We could use some other measures and that is completely the programmer's choice.\n",
    "\n",
    "So in our graph, our nodes are our movies and our edges are drawn based on the product of the PMI index and pair frequency for the two movies we are calculating the edge weight for. If this value exceeds our minimum weight (which is a hyperparameter defined by us, in this case, equal to 10) we draw an edge with the calculated weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "-RVP-s_Snxxh",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:21.949532Z",
     "start_time": "2023-05-16T10:21:21.937872Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RVP-s_Snxxh",
    "outputId": "abcd88e5-02bf-4060-878e-e4650dd132dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graph nodes: 1405\n",
      "Total number of graph edges: 40043\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of graph nodes:\", movies_graph.number_of_nodes())\n",
    "\n",
    "print(\"Total number of graph edges:\", movies_graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yrKGem28RoFU",
   "metadata": {
    "id": "yrKGem28RoFU"
   },
   "source": [
    "## **Calculating Average Degree**\n",
    "\n",
    "The average degree often gives us an idea about the inter-connectivity of the nodes. Let's see how we can interpret the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ma6Bl0Iknxxi",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:23.939346Z",
     "start_time": "2023-05-16T10:21:23.928770Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ma6Bl0Iknxxi",
    "outputId": "5450096b-3dcc-4910-d416-938f8f6ed4ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average node degree: 57.0\n"
     ]
    }
   ],
   "source": [
    "degrees = []\n",
    "\n",
    "for node in movies_graph.nodes:\n",
    "    \n",
    "    degrees.append(movies_graph.degree[node])\n",
    "\n",
    "print(\"Average node degree:\", round(sum(degrees) / len(degrees), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PCQdLE03R3SJ",
   "metadata": {
    "id": "PCQdLE03R3SJ"
   },
   "source": [
    "This average degree comes out to be 57 when we are taking the minimum weight to be 10. This gives us an idea that on average every node is connected to 57 other nodes. To look at it intuitively, this gives us the assurance that every movie would have suggestions for what to watch next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02S6YWctST4l",
   "metadata": {
    "id": "02S6YWctST4l"
   },
   "source": [
    "## **Creating Vocabulary lookup for Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "WZGhWh7ynxxi",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:25.640233Z",
     "start_time": "2023-05-16T10:21:25.631977Z"
    },
    "id": "WZGhWh7ynxxi"
   },
   "outputs": [],
   "source": [
    "vocabulary = [\"NA\"] + list(movies_graph.nodes)\n",
    "\n",
    "vocabulary_lookup = {token: idx for idx, token in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8Gbbu5cfTF08",
   "metadata": {
    "id": "8Gbbu5cfTF08"
   },
   "source": [
    "## **Traversing through our Graph: To pick the next node among all neighbors**\n",
    "\n",
    "The function 'next_step()' does the simple operation of traveling to the next node given you’re currently on a node, i.e., when you have watched a movie, what are the next movies you could consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "w4yi8qxYnxxj",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:26.485238Z",
     "start_time": "2023-05-16T10:21:26.472843Z"
    },
    "id": "w4yi8qxYnxxj"
   },
   "outputs": [],
   "source": [
    "def next_step(graph, previous, current, p, q):\n",
    "\n",
    "    neighbors = list(graph.neighbors(current))\n",
    "\n",
    "    weights = []\n",
    "\n",
    "    # Adjust the weights of the edges to the neighbors with the help of p and q so that we can control or give a preference to which category of nodes we would want to visit next\n",
    "\n",
    "    for neighbor in neighbors: # Looping through all the neighbors\n",
    "\n",
    "        if neighbor == previous:\n",
    "\n",
    "            # Control the probability to return to the previous node\n",
    "\n",
    "            weights.append(graph[current][neighbor][\"weight\"] / p)\n",
    "\n",
    "        elif graph.has_edge(neighbor, previous):\n",
    "\n",
    "            # The probability of visiting a local node\n",
    "\n",
    "            weights.append(graph[current][neighbor][\"weight\"])\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Control the probability to move forward\n",
    "\n",
    "            weights.append(graph[current][neighbor][\"weight\"] / q)\n",
    "\n",
    "    # Compute the probabilities of visiting each neighbor\n",
    "\n",
    "    weight_sum = sum(weights)\n",
    "\n",
    "    probabilities = [weight / weight_sum for weight in weights]\n",
    "\n",
    "    # Probabilistically select a neighbor to visit\n",
    "\n",
    "    next = np.random.choice(neighbors, size = 1, p = probabilities)[0]\n",
    "    \n",
    "    return next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l8Q_A0TcToCU",
   "metadata": {
    "id": "l8Q_A0TcToCU"
   },
   "source": [
    "Since each node in the graph is likely to have more than one neighbor (judging from the average degree, which was 57), we have to take a probabilistic approach. In other words, since we have more than one option for the next step, we assign probabilities to each edge arising from our current node/movie, and then we make our random choice based on those probabilities. \n",
    "\n",
    "Now here we have two hyperparameters, p and q, through which we can modify the probabilities a little. The value of q should lie between 1 and p. This is because the probability of visiting a node that has an edge with the current node as well as an edge with a previous node should be the greatest. The probability of a node that has an edge with the current node but not with the previous node should be lesser than the previous case. The probability of re-visiting this node should be the least. Therefore 1>q>p should be kept in mind while playing with these hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LlPZ8EKHVcOD",
   "metadata": {
    "id": "LlPZ8EKHVcOD"
   },
   "source": [
    "## **Creating Walks across our Graph**\n",
    "\n",
    "We want to generate sequences of movies that are connected with each other through edges inside the graph. These sequences can be later used to generate training data for training our Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "B2P6wPfPnxxj",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:27.934666Z",
     "start_time": "2023-05-16T10:21:27.919972Z"
    },
    "id": "B2P6wPfPnxxj"
   },
   "outputs": [],
   "source": [
    "def random_walk(graph, num_walks, num_steps, p, q):\n",
    "\n",
    "    walks = []\n",
    "\n",
    "    nodes = list(graph.nodes())\n",
    "\n",
    "    # Perform multiple iterations of the random walk\n",
    "\n",
    "    for walk_iteration in range(num_walks):\n",
    "\n",
    "        random.shuffle(nodes)\n",
    "\n",
    "        for node in tqdm(\n",
    "            \n",
    "            nodes,\n",
    "\n",
    "            position = 0,\n",
    "\n",
    "            leave = True,\n",
    "\n",
    "            desc = f\"Random walks iteration {walk_iteration + 1} of {num_walks}\",\n",
    "        ):\n",
    "            # Start the walk with a random node from the graph\n",
    "\n",
    "            walk = [node]\n",
    "\n",
    "            # Randomly walk for num_steps by calling the next_step function we created above\n",
    "            \n",
    "            while len(walk) < num_steps:\n",
    "                \n",
    "                current = walk[-1]  # Current node is the last element of the array 'walk'\n",
    "                \n",
    "                previous = walk[-2] if len(walk) > 1 else None  # If the length of our array 'walk' is more than one, then the previous node is the second last element of the array 'walk'\n",
    "                \n",
    "                next = next_step(graph, previous, current, p, q)  # Compute the next node to visit\n",
    "                \n",
    "                walk.append(next)  # Append the next node obtained to the array 'walk'\n",
    "\n",
    "            # Replace node ids (movieId) in the walk with token ids by looking at the vocabulary lookup\n",
    "\n",
    "            walk = [vocabulary_lookup[token] for token in walk]\n",
    "\n",
    "            # Add the walk to the generated sequence\n",
    "            \n",
    "            walks.append(walk)\n",
    "\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "goIiNVIWWKV2",
   "metadata": {
    "id": "goIiNVIWWKV2"
   },
   "source": [
    "This function has been created to create random walks with each walk having the number of movies defined by the num_steps argument. After we get each walk, we append them to an array, which we will use for generating our data for training the neural network through the generate_examples( ) function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hjFFxv7kgl_v",
   "metadata": {
    "id": "hjFFxv7kgl_v"
   },
   "source": [
    "## **Setting Hyperparameters for traversing through the Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "s6lZWTIgnxxk",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:43.702241Z",
     "start_time": "2023-05-16T10:21:34.677563Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s6lZWTIgnxxk",
    "outputId": "c11e907a-5d72-425c-ae55-a3ec436e7b7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random walks iteration 1 of 5: 100%|███████| 1405/1405 [00:01<00:00, 753.43it/s]\n",
      "Random walks iteration 2 of 5: 100%|███████| 1405/1405 [00:01<00:00, 755.26it/s]\n",
      "Random walks iteration 3 of 5: 100%|███████| 1405/1405 [00:01<00:00, 793.10it/s]\n",
      "Random walks iteration 4 of 5: 100%|███████| 1405/1405 [00:01<00:00, 799.56it/s]\n",
      "Random walks iteration 5 of 5: 100%|███████| 1405/1405 [00:01<00:00, 801.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of walks generated: 7025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Random walk return parameter\n",
    "\n",
    "p = 2\n",
    "\n",
    "# Random walk in-out parameter\n",
    "\n",
    "q = 1.5\n",
    "\n",
    "# Number of iterations of random walks\n",
    "\n",
    "num_walks = 5\n",
    "\n",
    "# Number of steps of each random walk\n",
    "\n",
    "num_steps = 10\n",
    "\n",
    "walks = random_walk(movies_graph, num_walks, num_steps, p, q)\n",
    "\n",
    "print(\"Number of walks generated:\", len(walks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TUKqSUSsZ9rZ",
   "metadata": {
    "id": "TUKqSUSsZ9rZ"
   },
   "source": [
    "We have set the value of p to 2, and q should lie between 1 and p. So we have chosen its value as 1.5. We can try out various combinations for these hyperparameters and check their result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZMqNznkRhKEO",
   "metadata": {
    "id": "ZMqNznkRhKEO"
   },
   "source": [
    "## **Generating Pairs of Movies that should have closer Embeddings**\n",
    "\n",
    "In the generate_examples( ) function, we use the skipgram function, which creates positive and negative samples. To get an intuition about positive and negative samples, please refer to the walkthrough document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eFj8wV86nxxk",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:53.355733Z",
     "start_time": "2023-05-16T10:21:46.750743Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFj8wV86nxxk",
    "outputId": "7f180e03-66e9-4a3b-f699-eb1b24ef9aae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating postive and negative examples: 100%|█| 7025/7025 [00:06<00:00, 1144.6\n"
     ]
    }
   ],
   "source": [
    "def generate_examples(sequences, window_size, num_negative_samples, vocabulary_size):\n",
    "\n",
    "    example_weights = defaultdict(int)\n",
    "    \n",
    "    # Iterate over all sequences (walks)\n",
    "\n",
    "    for sequence in tqdm(\n",
    "        \n",
    "        sequences,\n",
    "\n",
    "        position = 0,\n",
    "\n",
    "        leave = True,\n",
    "\n",
    "        desc = f\"Generating postive and negative examples\",\n",
    "    ):\n",
    "        \n",
    "        # Generate positive and negative skipgram pairs for a sequence or walk\n",
    "        \n",
    "        pairs, labels = keras.preprocessing.sequence.skipgrams(\n",
    "            \n",
    "            sequence,\n",
    "\n",
    "            vocabulary_size = vocabulary_size,\n",
    "\n",
    "            window_size = window_size,\n",
    "\n",
    "            negative_samples = num_negative_samples,\n",
    "\n",
    "        )\n",
    "        for idx in range(len(pairs)):  # Iterating through all pairs received from the skipgram function\n",
    "\n",
    "            pair = pairs[idx]  # Extracting the pair of movies\n",
    "\n",
    "            label = labels[idx]  # Extracting the labels\n",
    "\n",
    "            target, context = min(pair[0], pair[1]), max(pair[0], pair[1])\n",
    "\n",
    "            if target == context:\n",
    "             \n",
    "                continue\n",
    "\n",
    "            if(label == 1):  # If a positive sample is generated we label them 1, otherwise we label them 0  \n",
    "                \n",
    "                previous_negative_label = 0\n",
    "\n",
    "                previous_negative_entry = (target, context, previous_negative_label)\n",
    "\n",
    "                example_weights[previous_negative_entry] = 0  # Making the previous entry of the negative sample equal to zero because we have a positive sample now\n",
    "                \n",
    "                entry = (target, context, label)\n",
    "                \n",
    "                example_weights[entry] += 1\n",
    "            \n",
    "            if(label == 0):  # If a negative sample is generated\n",
    "                \n",
    "                querylabel = 1\n",
    "                \n",
    "                queryentry = (target, context, querylabel)  # We check if a positive sample with the same pair of movies exist   \n",
    "                \n",
    "                if ( example_weights[queryentry]>0):\n",
    "                \n",
    "                    continue  # We skip adding this entry to our entry if already a positive sample exists\n",
    "             \n",
    "                else:\n",
    "             \n",
    "                    entry = (target, context, label)\n",
    "             \n",
    "                    example_weights[entry] +=1  # If a positive sample doesn't exist, we add the negative example\n",
    "\n",
    "    targets, contexts, labels, weights = [], [], [], []\n",
    "\n",
    "    for entry in example_weights:\n",
    "    \n",
    "        weight = example_weights[entry]\n",
    "    \n",
    "        if(weight > 0):\n",
    "\n",
    "            target, context, label = entry  # Tuple unpacking of the 'entry' tuple\n",
    "            \n",
    "            targets.append(target)\n",
    "            \n",
    "            contexts.append(context)\n",
    "            \n",
    "            labels.append(label)\n",
    "            \n",
    "            weights.append(weight)\n",
    "\n",
    "    return np.array(targets), np.array(contexts), np.array(labels), np.array(weights)\n",
    "\n",
    "\n",
    "num_negative_samples = 4\n",
    "\n",
    "targets, contexts, labels, weights = generate_examples(\n",
    "\n",
    "    sequences = walks,\n",
    "\n",
    "    window_size = num_steps,\n",
    "    \n",
    "    num_negative_samples = num_negative_samples,\n",
    "\n",
    "    vocabulary_size = len(vocabulary),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RdL_p-wWiHQJ",
   "metadata": {
    "id": "RdL_p-wWiHQJ"
   },
   "source": [
    "The above function generate_examples() calls skipgram function of keras.preprocessing. The skipgram function takes a corpus and generates pairs of words. If both words in the pair are a part of the corpus, we label them 1. Otherwise, we label them 0. Here our corpus is the array of random walks. So skipgram generates pairs of movies. If both of those movies have been present in a particular random walk, they are labeled as 1, otherwise 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4P1KFFKUnxxk",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:56.159680Z",
     "start_time": "2023-05-16T10:21:56.151054Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4P1KFFKUnxxk",
    "outputId": "34d457e6-c81c-4d53-cd21-8ebd32cf0151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets shape: (729387,)\n",
      "Contexts shape: (729387,)\n",
      "Labels shape: (729387,)\n",
      "Weights shape: (729387,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets shape: {targets.shape}\")\n",
    "\n",
    "print(f\"Contexts shape: {contexts.shape}\")\n",
    "\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "print(f\"Weights shape: {weights.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Doi8os-5jRv2",
   "metadata": {
    "id": "Doi8os-5jRv2"
   },
   "source": [
    "## **Generating Data in a Classification format for our Neural Network Training**\n",
    "\n",
    "Our data needs to be in a particular format so that it fits our Neural network architecture inputs. Let's do that through these pre-processing activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "RL_0uL3Xnxxl",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:58.145614Z",
     "start_time": "2023-05-16T10:21:58.096018Z"
    },
    "id": "RL_0uL3Xnxxl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "def create_dataset(targets, contexts, labels, weights, batch_size):\n",
    "\n",
    "    inputs = {\n",
    "\n",
    "        \"target\": targets,\n",
    "\n",
    "        \"context\": contexts,\n",
    "\n",
    "    }  # Pre-processing the targets, contexts, and labels vectors to fit our Neural Network pipeline \n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((inputs, labels, weights))\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size = batch_size * 2)  # Shuffling the data set to remove any chance of sequential data\n",
    "    \n",
    "    dataset = dataset.batch(batch_size, drop_remainder = True)\n",
    "\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    " \n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = create_dataset(\n",
    "\n",
    "    targets = targets,\n",
    "\n",
    "    contexts = contexts,\n",
    "\n",
    "    labels = labels,\n",
    "    \n",
    "    weights = weights,\n",
    "    \n",
    "    batch_size = batch_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aIuLCiGj1Pl",
   "metadata": {
    "id": "4aIuLCiGj1Pl"
   },
   "source": [
    "The output of the generate_example gives us target, context, and label vectors. So from these three vectors, we create our own dataset for a classification task, where target and context movies would be our independent variables. And the label would be our dependent variable. And we build a Neural Network in a way so that it takes a look at the target movie and the context movie and it can predict the label value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rCmlKoAZlUUt",
   "metadata": {
    "id": "rCmlKoAZlUUt"
   },
   "source": [
    "## **Hyperparameters for Neural Network Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "I-y6Q0eanxxl",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:22:01.743327Z",
     "start_time": "2023-05-16T10:22:01.736256Z"
    },
    "id": "I-y6Q0eanxxl"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ne7kaaV0ljBF",
   "metadata": {
    "id": "ne7kaaV0ljBF"
   },
   "source": [
    "## **Creating our Model**\n",
    "\n",
    "Let's build a Neural Network Architecture which would take the target and context movie as input and try to predict the output label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "EDu3hhYQnxxm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:22:03.024380Z",
     "start_time": "2023-05-16T10:22:03.009789Z"
    },
    "id": "EDu3hhYQnxxm"
   },
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size, embedding_dim):\n",
    "\n",
    "    inputs = {\n",
    "\n",
    "        \"target\": layers.Input(name = \"target\", shape = (), dtype = \"int32\"),\n",
    "\n",
    "        \"context\": layers.Input(name = \"context\", shape = (), dtype = \"int32\"),\n",
    "\n",
    "    }\n",
    "    # Initialize item embeddings\n",
    "    \n",
    "    embed_item = layers.Embedding(\n",
    "    \n",
    "        input_dim = vocabulary_size,\n",
    "        \n",
    "        output_dim = embedding_dim,\n",
    "        \n",
    "        embeddings_initializer = \"he_normal\",\n",
    "        \n",
    "        embeddings_regularizer = keras.regularizers.l2(1e-6),\n",
    "        \n",
    "        name=\"item_embeddings\",\n",
    "    )\n",
    "    \n",
    "    # Lookup embeddings for the target\n",
    "\n",
    "    target_embeddings = embed_item(inputs[\"target\"])\n",
    "    \n",
    "    # Lookup embeddings for the context\n",
    "    \n",
    "    context_embeddings = embed_item(inputs[\"context\"])\n",
    "    \n",
    "    # Compute dot similarity between target and context embeddings\n",
    "    \n",
    "    logits = layers.Dot(axes = 1, normalize = False, name = \"dot_similarity\")(\n",
    "        \n",
    "        [target_embeddings, context_embeddings]\n",
    "    )\n",
    "\n",
    "    # Create the model\n",
    "    \n",
    "    model = keras.Model(inputs = inputs, outputs = logits)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KBQUhTuulnd0",
   "metadata": {
    "id": "KBQUhTuulnd0"
   },
   "source": [
    "This model is fairly simple. There is an Embedding layer that converts the target and context to target embeddings and context embeddings, respectively. Then we take the dot product of these two embeddings to get an output on the scale of 0 to 1. This way it tries to train with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "DSQhpEftnxxm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:22:06.627631Z",
     "start_time": "2023-05-16T10:22:06.519327Z"
    },
    "id": "DSQhpEftnxxm"
   },
   "outputs": [],
   "source": [
    "model = create_model(len(vocabulary), embedding_dim)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(learning_rate),\n",
    "\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "\n",
    ")  # Setting up the model's optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5WCKuKms9l",
   "metadata": {
    "id": "de5WCKuKms9l"
   },
   "source": [
    "## **Visualizing the Model**\n",
    "\n",
    "Keras comes with an in-built visualization tool. Let's use that and visualize our architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ZH0AR3Onnxxn",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:22:17.729099Z",
     "start_time": "2023-05-16T10:22:17.718320Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "ZH0AR3Onnxxn",
    "outputId": "d203c1b5-1e37-4326-c07f-a214ac6492bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(\n",
    "\n",
    "    model, show_shapes = True, show_dtype = True, show_layer_names = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Uiiqut75m3H7",
   "metadata": {
    "id": "Uiiqut75m3H7"
   },
   "source": [
    "## **Training Phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "h3h6bwxOnxxn",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:23:09.734788Z",
     "start_time": "2023-05-16T10:22:31.327458Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3h6bwxOnxxn",
    "outputId": "a6f05ee4-8234-4e33-e0b0-edb721e1f65f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "712/712 [==============================] - 4s 5ms/step - loss: 2.1016\n",
      "Epoch 2/10\n",
      "712/712 [==============================] - 4s 5ms/step - loss: 1.7524\n",
      "Epoch 3/10\n",
      "712/712 [==============================] - 4s 5ms/step - loss: 1.6875\n",
      "Epoch 4/10\n",
      "712/712 [==============================] - 4s 5ms/step - loss: 1.6597\n",
      "Epoch 5/10\n",
      "712/712 [==============================] - 4s 5ms/step - loss: 1.6414\n",
      "Epoch 6/10\n",
      "712/712 [==============================] - 4s 5ms/step - loss: 1.6278\n",
      "Epoch 7/10\n",
      "712/712 [==============================] - 4s 5ms/step - loss: 1.6158\n",
      "Epoch 8/10\n",
      "712/712 [==============================] - 4s 5ms/step - loss: 1.6033\n",
      "Epoch 9/10\n",
      "712/712 [==============================] - 4s 5ms/step - loss: 1.5889\n",
      "Epoch 10/10\n",
      "712/712 [==============================] - 4s 5ms/step - loss: 1.5726\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eumd6Bv7nxxn",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:23:12.557900Z",
     "start_time": "2023-05-16T10:23:12.439195Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "eumd6Bv7nxxn",
    "outputId": "a97a782a-3595-48b6-d808-21128e9938a5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paec_0SOnEst",
   "metadata": {
    "id": "paec_0SOnEst"
   },
   "source": [
    "## **Extracting the Embedding Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "l1UUp_PZnxxo",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:23:16.162764Z",
     "start_time": "2023-05-16T10:23:16.149489Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1UUp_PZnxxo",
    "outputId": "fe4d4d02-a45d-44ec-cc5a-263ce366b022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (1406, 50)\n"
     ]
    }
   ],
   "source": [
    "movie_embeddings = model.get_layer(\"item_embeddings\").get_weights()[0]  # Extracting the layer weight by layer name\n",
    "\n",
    "print(\"Embeddings shape:\", movie_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L9xCSG7cnQYr",
   "metadata": {
    "id": "L9xCSG7cnQYr"
   },
   "source": [
    "We had created a self-supervised task and now we take out the embedding vectors so that we can directly check for similarity among any two movies after they are converted to their particular movie_id by the get_movie_id_by_title()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cRyUwj07nxxo",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:23:18.450045Z",
     "start_time": "2023-05-16T10:23:18.442146Z"
    },
    "id": "cRyUwj07nxxo"
   },
   "outputs": [],
   "source": [
    "query_movies = [\n",
    "\n",
    "    \"Matrix, The (1999)\",\n",
    "\n",
    "    \"Star Wars: Episode IV - A New Hope (1977)\",\n",
    "\n",
    "    \"Lion King, The (1994)\",\n",
    "\n",
    "    \"Terminator 2: Judgment Day (1991)\",\n",
    "\n",
    "    \"Godfather, The (1972)\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HuxMzgzupQy0",
   "metadata": {
    "id": "HuxMzgzupQy0"
   },
   "source": [
    "## **Converting Query movies to Query Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "QtlGH6X7nxxo",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:23:20.113049Z",
     "start_time": "2023-05-16T10:23:20.093545Z"
    },
    "id": "QtlGH6X7nxxo"
   },
   "outputs": [],
   "source": [
    "query_embeddings = []\n",
    "\n",
    "for movie_title in query_movies:\n",
    "\n",
    "    movieId = get_movie_id_by_title(movie_title)  # Getting id from the title of the movie\n",
    "    \n",
    "    token_id = vocabulary_lookup[movieId]  # Getting index to lookup for embedding task\n",
    "    \n",
    "    movie_embedding = movie_embeddings[token_id]  # Getting embedding for query movies\n",
    "    \n",
    "    query_embeddings.append(movie_embedding)\n",
    "\n",
    "query_embeddings = np.array(query_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9xDw1fIFpdAU",
   "metadata": {
    "id": "9xDw1fIFpdAU"
   },
   "source": [
    "## **Finding the top 5 similar Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hmELYQSanxxo",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:23:21.589058Z",
     "start_time": "2023-05-16T10:23:21.356068Z"
    },
    "id": "hmELYQSanxxo"
   },
   "outputs": [],
   "source": [
    "similarities = tf.linalg.matmul(\n",
    "\n",
    "    tf.math.l2_normalize(query_embeddings),  # Normalizing the results of multiplication to get output of dot product on a scale of 0 to 1\n",
    "    \n",
    "    tf.math.l2_normalize(movie_embeddings),\n",
    "    \n",
    "    transpose_b = True,\n",
    ")\n",
    "\n",
    "_, indices = tf.math.top_k(similarities, k = 5)\n",
    "\n",
    "indices = indices.numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tW25JTskpo_l",
   "metadata": {
    "id": "tW25JTskpo_l"
   },
   "source": [
    "## **Converting those top 5 Embeddings to Movie titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9nt8qE6jnxxp",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:23:23.547839Z",
     "start_time": "2023-05-16T10:23:23.515047Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nt8qE6jnxxp",
    "outputId": "c4defea4-8b8a-4cb8-9aa2-d7c8e6b20f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix, The (1999)\n",
      "------------------\n",
      "- Matrix, The (1999)\n",
      "- Dark Knight, The (2008)\n",
      "- Fight Club (1999)\n",
      "- Lord of the Rings: The Return of the King, The (2003)\n",
      "- Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
      "\n",
      "Star Wars: Episode IV - A New Hope (1977)\n",
      "-----------------------------------------\n",
      "- Star Wars: Episode IV - A New Hope (1977)\n",
      "- Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "- Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "- Reservoir Dogs (1992)\n",
      "- Monty Python and the Holy Grail (1975)\n",
      "\n",
      "Lion King, The (1994)\n",
      "---------------------\n",
      "- Lion King, The (1994)\n",
      "- Braveheart (1995)\n",
      "- Forrest Gump (1994)\n",
      "- Beauty and the Beast (1991)\n",
      "- Die Hard: With a Vengeance (1995)\n",
      "\n",
      "Terminator 2: Judgment Day (1991)\n",
      "---------------------------------\n",
      "- Terminator 2: Judgment Day (1991)\n",
      "- Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
      "- Braveheart (1995)\n",
      "- Aliens (1986)\n",
      "- Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "\n",
      "Godfather, The (1972)\n",
      "---------------------\n",
      "- Godfather, The (1972)\n",
      "- Rear Window (1954)\n",
      "- Casablanca (1942)\n",
      "- Citizen Kane (1941)\n",
      "- Apocalypse Now (1979)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, title in enumerate(query_movies):\n",
    "\n",
    "    print(title)\n",
    "\n",
    "    print(\"\".rjust(len(title), \"-\"))\n",
    "\n",
    "    similar_tokens = indices[idx]\n",
    "\n",
    "    for token in similar_tokens:\n",
    "\n",
    "        similar_movieId = vocabulary[token]\n",
    "\n",
    "        similar_title = get_movie_title_by_id(similar_movieId)\n",
    "\n",
    "        print(f\"- {similar_title}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lqO4Os5t5P5U",
   "metadata": {
    "id": "lqO4Os5t5P5U"
   },
   "source": [
    "## **Conclusion**\n",
    "\n",
    "- We have converted our user data which had ratings for movies to a self-supervised task of training an embedding vector, which is ultimately helping us in suggesting top 'k' similar movies for a particular.\n",
    "- We have used techniques of random walks and skipgram models to generate examples of pairs of similar nodes that help in node embedding.\n",
    "- We have used a graph neural network to solve a recommendation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae820fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Notebook_Movie_Recommendation_using_Graph_Neural_Networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
